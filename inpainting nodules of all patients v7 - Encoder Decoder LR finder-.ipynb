{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code adapted from: https://github.com/DmitryUlyanov/deep-image-prior/blob/master/inpainting.ipynb   \n",
    "\n",
    "\n",
    "**v7**     \n",
    "1. LR finder with Encoder-Decoder\n",
    "\n",
    "**v6**     \n",
    "1. LR finder with UNet\n",
    "1. The conv definitin in common.py was modified to apply Xavier initialization to ONLY to the weights (not biases)\n",
    "\n",
    "**v5**     \n",
    "1. UNet   \n",
    "\n",
    "**v4**     \n",
    "1. Cyclic learning rate   \n",
    "\n",
    "**v3**     \n",
    "1. Include learning rate annealing every 300 epochs (set annealing=**True** in optimize2).    \n",
    "\n",
    "**v2**     \n",
    "1. We save the output for each epoch only if the loss is lower   \n",
    "    1. This required a modification in **optimize2** (previously named optimize)   \n",
    "1. We optionally save the output if the loss is lower, and only after the 500th iteration   \n",
    "    1. We moved the **plot_for_gif** function inside the **optimize2** function \n",
    "\n",
    "**v1**     \n",
    "1. The following files in the deep image prior library are modified:\n",
    "    1. utils.common_utils.py: **optimize** now returns loss   \n",
    "    1. utils.common_utils.py: **plot_image_grid** plots viridis without interpolation\n",
    "1. **To do:** Save the output with the lowest loss not the one at the k-iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from models.resnet import ResNet\n",
    "from models.unet import UNet\n",
    "from models.skip import skip\n",
    "import torch\n",
    "import torch.optim\n",
    "\n",
    "from utils.inpainting_utils import *\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =True\n",
    "dtype = torch.cuda.FloatTensor\n",
    "\n",
    "PLOT = True\n",
    "imsize = -1\n",
    "dim_div_by = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from matplotlib import rcParams\n",
    "from copy import copy\n",
    "from scipy import ndimage\n",
    "import time\n",
    "from scipy import ndimage as ndi\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook\n",
    "from skimage import measure, morphology\n",
    "from itertools import groupby, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import watershed\n",
    "from skimage.feature import peak_local_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_rcParams(true_or_false):\n",
    "    rcParams['ytick.left']=true_or_false\n",
    "    rcParams['ytick.right']=true_or_false\n",
    "    rcParams['xtick.top']=true_or_false\n",
    "    rcParams['xtick.bottom']=true_or_false\n",
    "    rcParams['ytick.labelleft'] = true_or_false\n",
    "    rcParams['ytick.labelright'] = true_or_false\n",
    "    rcParams['xtick.labeltop'] = true_or_false\n",
    "    rcParams['xtick.labelbottom'] = true_or_false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_for_gif(image_to_save,num_iter, i):\n",
    "    fig, ax = plt.subplots(1,2, gridspec_kw = {'width_ratios':[8, 1]}, figsize=(14,10))\n",
    "    ax[0].imshow(image_to_save, cmap='viridis')\n",
    "    ax[0].axis('off')\n",
    "    ax[1].axvline(x=.5, c='k')\n",
    "    ax[1].scatter(.5, i, c='k')\n",
    "    ax[1].set_ylim([num_iter, 0])\n",
    "    ax[1].yaxis.tick_right()\n",
    "    ax[1].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False) \n",
    "    # ax[1].xticks([], [])\n",
    "    ax[1].spines[\"top\"].set_visible(False)\n",
    "    ax[1].spines[\"bottom\"].set_visible(False)\n",
    "    ax[1].spines[\"left\"].set_visible(False)\n",
    "    ax[1].spines[\"right\"].set_visible(False)\n",
    "    plt.subplots_adjust(wspace=.04, hspace=0)\n",
    "    plt.savefig(f'{path_img_dest}images before gifs/iter {i:5d}.jpeg',\n",
    "                bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close(fig)\n",
    "    #return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # To create folders for new experiment version\n",
    "# os.chdir('dip results all 7')\n",
    "# for i in ['arrays', 'differences', 'gifs', 'images before gifs']:\n",
    "#     os.makedirs(i)\n",
    "# os.chdir('arrays')\n",
    "# for i in ['last', 'orig']:\n",
    "#     os.makedirs(i)\n",
    "# os.chdir('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsh=np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_original(image_to_save, id_name, name_extension, error_final=-1):\n",
    "    name_extension = str(name_extension)\n",
    "    fig, ax = plt.subplots(1,2, gridspec_kw = {'width_ratios':[8, 1]}, figsize=(14,10))\n",
    "    ax[0].imshow(image_to_save, cmap='viridis')\n",
    "    ax[0].axis('off')\n",
    "    ax[1].axvline(x=.5, c='k')\n",
    "    ax[1].set_ylim([num_iter, 0])\n",
    "    ax[1].yaxis.tick_right()\n",
    "    ax[1].tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False) \n",
    "    ax[1].spines[\"top\"].set_visible(False)\n",
    "    ax[1].spines[\"bottom\"].set_visible(False)\n",
    "    ax[1].spines[\"left\"].set_visible(False)\n",
    "    ax[1].spines[\"right\"].set_visible(False)\n",
    "    plt.subplots_adjust(wspace=.04, hspace=0)\n",
    "    if error_final==-1: # for original\n",
    "        fig.savefig(f'{path_img_dest}gifs/dip {id_name} {name_extension}.jpeg',\n",
    "                    bbox_inches = 'tight',pad_inches = 0)\n",
    "    else:\n",
    "        fig.savefig(f'{path_img_dest}gifs/dip {id_name} {name_extension} {error_final:05d}.jpeg',\n",
    "                    bbox_inches = 'tight',pad_inches = 0)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_3d(image, threshold=-300, alpha=.70, fig_size=10):\n",
    "    \n",
    "    # Position the scan upright, \n",
    "    # so the head of the patient would be at the top facing the camera\n",
    "    p = image.transpose(2,1,0)\n",
    "    \n",
    "    verts, faces, x,y = measure.marching_cubes(p, threshold)\n",
    "\n",
    "    fig = plt.figure(figsize=(fig_size, fig_size))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Fancy indexing: `verts[faces]` to generate a collection of triangles\n",
    "    mesh = Poly3DCollection(verts[faces], alpha=alpha)\n",
    "    face_color = [0.45, 0.45, 0.75]\n",
    "    mesh.set_facecolor(face_color)\n",
    "    ax.add_collection3d(mesh)\n",
    "\n",
    "    ax.set_xlim(0, p.shape[0])\n",
    "    ax.set_ylim(0, p.shape[1])\n",
    "    ax.set_zlim(0, p.shape[2])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_slices(new_name):\n",
    "    \"\"\"Read slices of lung, mask outside lungs and nodule, mask nodule, mask outside\"\"\"\n",
    "    idname = new_name.split('_')[0]\n",
    "    file_lung = np.load(f'{path_data}lungs/{new_name}')\n",
    "    file_mask = np.load(f'{path_data}masks/{new_name}')\n",
    "    file_nodule = np.load(f'{path_data}nodule to focus on/{new_name}')\n",
    "    file_outside  = np.load(f'{path_data}outside lungs mask/{new_name}')\n",
    "    lungs_slice = file_lung.f.arr_0\n",
    "    mask_slice = file_mask.f.arr_0\n",
    "    nodule = file_nodule.f.arr_0\n",
    "    outside_lungs = file_outside.f.arr_0\n",
    "    return lungs_slice, mask_slice, nodule, outside_lungs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_images_right_size(lungs_slice, mask_slice, nodule, outside_lungs):\n",
    "    \"\"\"Make the images the right size \n",
    "    The encoder-decoder has five blocks (the one initially evalluated), \n",
    "    therefore, each side has to be divisible by a factor of 32 (2^5)\"\"\"\n",
    "    factor = 32\n",
    "    pad_dim_0 = factor - nsh(lungs_slice)[0] % factor\n",
    "    pad_dim_1 = factor - nsh(lungs_slice)[1] % factor\n",
    "\n",
    "    mask_slice = 1 - mask_slice\n",
    "\n",
    "    lungs_slice = np.pad(lungs_slice, ((0,pad_dim_0), (0,0)), mode='constant')\n",
    "    lungs_slice = np.pad(lungs_slice, ((0,0), (0,pad_dim_1)), mode='constant')\n",
    "    mask_slice = np.pad(mask_slice, ((0,pad_dim_0), (0,0)), mode='constant')\n",
    "    mask_slice = np.pad(mask_slice, ((0,0), (0,pad_dim_1)), mode='constant')\n",
    "    outside_lungs = np.pad(outside_lungs, ((0,pad_dim_0), (0,0)), mode='constant', constant_values=1)\n",
    "    outside_lungs = np.pad(outside_lungs, ((0,0), (0,pad_dim_1)), mode='constant', constant_values=1)\n",
    "\n",
    "    lungs_slice = (lungs_slice - np.min(lungs_slice))/(np.max(lungs_slice)-np.min(lungs_slice))\n",
    "\n",
    "    lungs_slice = np.expand_dims(lungs_slice, 0)\n",
    "    mask_slice = np.expand_dims(mask_slice, 0)\n",
    "    outside_lungs = np.expand_dims(outside_lungs, 0)\n",
    "\n",
    "    img_np = lungs_slice\n",
    "    img_mask_np = mask_slice\n",
    "    return img_np, img_mask_np, outside_lungs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    \n",
    "    global i\n",
    "    \n",
    "    images_all = []\n",
    "#     image_to_save= [] \n",
    "    \n",
    "    if param_noise:\n",
    "        for n in [x for x in net.parameters() if len(x.size()) == 4]:\n",
    "            n = n + n.detach().clone().normal_() * n.std() / 50\n",
    "    \n",
    "    net_input = net_input_saved\n",
    "    if reg_noise_std > 0:\n",
    "        net_input = net_input_saved + (noise.normal_() * reg_noise_std)\n",
    "        \n",
    "        \n",
    "    out = net(net_input)\n",
    "#     print(np.shape(out))\n",
    "    total_loss = mse(out * mask_var, img_var * mask_var)\n",
    "    total_loss.backward()\n",
    "        \n",
    "    print ('Iteration %05d    Loss %f' % (i, total_loss.item()), '\\r', end='')\n",
    "    #if  PLOT and i % show_every == 0:\n",
    "    if  PLOT:\n",
    "        out_np = torch_to_np(out)\n",
    "        if np.shape(out_np)[0] == 1:\n",
    "            image_to_save = out_np[0]\n",
    "        #plot_image_grid([np.clip(out_np, 0, 1)], factor=figsize, nrow=1) # DEL original fun\n",
    "        #plot_for_gif(image_to_save, num_iter, i) # DEL save images to make gif\n",
    "        images_all.append(image_to_save)\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "#     if  PLOT and i % show_every == 0: image_generated = image_to_save\n",
    "#     else: image_generated = []\n",
    "    \n",
    "    return total_loss, images_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = f'/data/OMM/Datasets/LIDC_other_formats/LIDC slices inpainting/'\n",
    "path_img_dest = 'dip results all 7/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NET_TYPE = 'skip_depth6' # one of skip_depth4|skip_depth2|UNET|ResNet\n",
    "pad = 'reflection' # 'zero'\n",
    "OPT_OVER = 'net'\n",
    "OPTIMIZER = 'adam'\n",
    "INPUT = 'noise'\n",
    "input_depth = 1\n",
    "LR = 0.000001 \n",
    "num_iter = 10001\n",
    "param_noise = False\n",
    "show_every = 500\n",
    "figsize = 5\n",
    "reg_noise_std = 0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-7\n",
    "LRs = []\n",
    "for i in range(1000):\n",
    "    LR *= 1.1\n",
    "    if LR >= 1: break\n",
    "    LRs.append(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc12b8da208>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(LRs))\n",
    "plt.plot(LRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(f'{path_data}lungs/')\n",
    "files = np.sort(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "691dcffac6574e3cb3f5dc79efe1cc77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2259), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample = 878\n",
      "Finding LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/om18/anaconda3/envs/pytorch/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:122: UserWarning: nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.Upsampling is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training initialization 0 with LR = 0.00008\n",
      "LR reduced to: 0.00001s 0.000010 \n",
      "training stopped at it 3569 after 500 iterations without improvement\n",
      "-89.868 s\n",
      "\n",
      "sample = 879\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00002\n",
      "-255.163 s10000    Loss 0.000003 \n",
      "\n",
      "sample = 880\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00004\n",
      "LR reduced to: 0.00000s 0.000003 \n",
      "training stopped at it 7892 after 500 iterations without improvement\n",
      "-198.378 s\n",
      "\n",
      "sample = 881\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00004\n",
      "LR reduced to: 0.00000s 0.000007 \n",
      "-254.960 s10000    Loss 0.000003 \n",
      "\n",
      "sample = 882\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00004\n",
      "LR reduced to: 0.00000s 0.000192 \n",
      "training stopped at it 1360 after 500 iterations without improvement\n",
      "-41.688 s\n",
      "\n",
      "sample = 883\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00005\n",
      "LR reduced to: 0.00001s 0.000228 \n",
      "training stopped at it 1782 after 500 iterations without improvement\n",
      "-54.411 s\n",
      "\n",
      "sample = 884\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00011\n",
      "LR reduced to: 0.00001s 0.000073 \n",
      "LR reduced to: 0.00000s 0.000063 \n",
      "training stopped at it 3741 after 500 iterations without improvement\n",
      "-115.675 s\n",
      "\n",
      "sample = 885\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000195 \n",
      "training stopped at it 1252 after 500 iterations without improvement\n",
      "-38.460 s\n",
      "\n",
      "sample = 886\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00003\n",
      "LR reduced to: 0.00000s 0.000193 \n",
      "training stopped at it 1966 after 500 iterations without improvement\n",
      "-60.554 s\n",
      "\n",
      "sample = 887\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00005\n",
      "LR reduced to: 0.00000s 0.000191 \n",
      "training stopped at it 1284 after 500 iterations without improvement\n",
      "-39.673 s\n",
      "\n",
      "sample = 888\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00008\n",
      "LR reduced to: 0.00001s 0.000025 \n",
      "training stopped at it 5549 after 500 iterations without improvement\n",
      "-151.938 s\n",
      "\n",
      "sample = 889\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00005\n",
      "LR reduced to: 0.00000s 0.000007 \n",
      "training stopped at it 4997 after 500 iterations without improvement\n",
      "-136.320 s\n",
      "\n",
      "sample = 890\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00008\n",
      "LR reduced to: 0.00001s 0.000032 \n",
      "training stopped at it 7214 after 500 iterations without improvement\n",
      "-182.853 s\n",
      "\n",
      "sample = 891\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00012\n",
      "LR reduced to: 0.00001s 0.000009 \n",
      "training stopped at it 5553 after 500 iterations without improvement\n",
      "-140.969 s\n",
      "\n",
      "sample = 892\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00010\n",
      "LR reduced to: 0.00001s 0.000085 \n",
      "training stopped at it 6033 after 500 iterations without improvement\n",
      "-152.931 s\n",
      "\n",
      "sample = 893\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000041 \n",
      "training stopped at it 4418 after 500 iterations without improvement\n",
      "-111.492 s\n",
      "\n",
      "sample = 894\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00004\n",
      "-253.613 s10000    Loss 0.000002 \n",
      "\n",
      "sample = 895\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00005\n",
      "LR reduced to: 0.00001s 0.000005 \n",
      "training stopped at it 7624 after 500 iterations without improvement\n",
      "-192.486 s\n",
      "\n",
      "sample = 896\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00008\n",
      "LR reduced to: 0.00001s 0.000036 \n",
      "training stopped at it 2589 after 500 iterations without improvement\n",
      "-65.476 s\n",
      "\n",
      "sample = 897\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00008\n",
      "LR reduced to: 0.00001s 0.000032 \n",
      "-255.007 s10000    Loss 0.000009 \n",
      "\n",
      "sample = 898\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00009\n",
      "LR reduced to: 0.00001s 0.000010 \n",
      "training stopped at it 5850 after 500 iterations without improvement\n",
      "-149.412 s\n",
      "\n",
      "sample = 899\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00008\n",
      "LR reduced to: 0.00001s 0.000014 \n",
      "training stopped at it 4977 after 500 iterations without improvement\n",
      "-127.203 s\n",
      "\n",
      "sample = 900\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00006\n",
      "LR reduced to: 0.00001s 0.000013 \n",
      "training stopped at it 5600 after 500 iterations without improvement\n",
      "-141.878 s\n",
      "\n",
      "sample = 901\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000015 \n",
      "training stopped at it 3000 after 500 iterations without improvement\n",
      "-76.645 s\n",
      "\n",
      "sample = 902\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000014 \n",
      "training stopped at it 6495 after 500 iterations without improvement\n",
      "-164.908 s\n",
      "\n",
      "sample = 903\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00009\n",
      "-273.638 s10000    Loss 0.000002 \n",
      "\n",
      "sample = 904\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000002 \n",
      "-273.175 s10000    Loss 0.000002 \n",
      "\n",
      "sample = 905\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00004\n",
      "LR reduced to: 0.00000s 0.000002 \n",
      "-272.717 s10000    Loss 0.000002 \n",
      "\n",
      "sample = 906\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00009\n",
      "LR reduced to: 0.00001s 0.000014 \n",
      "training stopped at it 5093 after 500 iterations without improvement\n",
      "-146.987 s\n",
      "\n",
      "sample = 907\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00011\n",
      "LR reduced to: 0.00001s 0.000049 \n",
      "training stopped at it 5226 after 500 iterations without improvement\n",
      "-150.240 s\n",
      "\n",
      "sample = 908\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00005\n",
      "LR reduced to: 0.00001s 0.000027 \n",
      "-286.892 s10000    Loss 0.000013 \n",
      "\n",
      "sample = 909\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00004\n",
      "LR reduced to: 0.00000s 0.000040 \n",
      "training stopped at it 4146 after 500 iterations without improvement\n",
      "-106.808 s\n",
      "\n",
      "sample = 910\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00011\n",
      "LR reduced to: 0.00001s 0.000027 \n",
      "training stopped at it 4176 after 500 iterations without improvement\n",
      "-107.146 s\n",
      "\n",
      "sample = 911\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00004\n",
      "LR reduced to: 0.00000s 0.000010 \n",
      "training stopped at it 6718 after 500 iterations without improvement\n",
      "-172.396 s\n",
      "\n",
      "sample = 912\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00003\n",
      "LR reduced to: 0.00000s 0.000003 \n",
      "-271.742 s10000    Loss 0.000003 \n",
      "\n",
      "sample = 913\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00004\n",
      "-271.481 s10000    Loss 0.000004 \n",
      "\n",
      "sample = 914\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00004\n",
      "LR reduced to: 0.00000s 0.000030 \n",
      "training stopped at it 5237 after 500 iterations without improvement\n",
      "-142.392 s\n",
      "\n",
      "sample = 915\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00008\n",
      "LR reduced to: 0.00001s 0.000055 \n",
      "training stopped at it 4133 after 500 iterations without improvement\n",
      "-112.655 s\n",
      "\n",
      "sample = 916\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000012 \n",
      "training stopped at it 5866 after 500 iterations without improvement\n",
      "-159.738 s\n",
      "\n",
      "sample = 917\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00020\n",
      "LR reduced to: 0.00002s 0.000021 \n",
      "training stopped at it 3148 after 500 iterations without improvement\n",
      "-86.167 s\n",
      "\n",
      "sample = 918\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000020 \n",
      "training stopped at it 5139 after 500 iterations without improvement\n",
      "-140.099 s\n",
      "\n",
      "sample = 919\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00004\n",
      "LR reduced to: 0.00000s 0.000009 \n",
      "training stopped at it 9005 after 500 iterations without improvement\n",
      "-244.343 s\n",
      "\n",
      "sample = 920\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00005\n",
      "-272.430 s10000    Loss 0.000004 \n",
      "\n",
      "sample = 921\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00008\n",
      "LR reduced to: 0.00001s 0.000008 \n",
      "training stopped at it 5361 after 500 iterations without improvement\n",
      "-145.385 s\n",
      "\n",
      "sample = 922\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00004\n",
      "LR reduced to: 0.00000s 0.000005 \n",
      "training stopped at it 6397 after 500 iterations without improvement\n",
      "-174.342 s\n",
      "\n",
      "sample = 923\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00003\n",
      "-272.864 s10000    Loss 0.000003 \n",
      "\n",
      "sample = 924\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000003 \n",
      "training stopped at it 6274 after 500 iterations without improvement\n",
      "-170.535 s\n",
      "\n",
      "sample = 925\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00006\n",
      "LR reduced to: 0.00001s 0.000008 \n",
      "training stopped at it 4570 after 500 iterations without improvement\n",
      "-106.481 s\n",
      "\n",
      "sample = 926\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00006\n",
      "LR reduced to: 0.00001s 0.000002 \n",
      "training stopped at it 6443 after 500 iterations without improvement\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-150.140 s\n",
      "\n",
      "sample = 927\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00010\n",
      "LR reduced to: 0.00001s 0.000205 \n",
      "LR reduced to: 0.00000s 0.000163 \n",
      "training stopped at it 1651 after 500 iterations without improvement\n",
      "-49.469 s\n",
      "\n",
      "sample = 928\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00008\n",
      "LR reduced to: 0.00001s 0.000181 \n",
      "training stopped at it 1536 after 500 iterations without improvement\n",
      "-46.243 s\n",
      "\n",
      "sample = 929\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000218 \n",
      "training stopped at it 1474 after 500 iterations without improvement\n",
      "-44.470 s\n",
      "\n",
      "sample = 930\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00013\n",
      "LR reduced to: 0.00001s 0.000169 \n",
      "training stopped at it 1111 after 500 iterations without improvement\n",
      "-33.655 s\n",
      "\n",
      "sample = 931\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00003\n",
      "-287.180 s10000    Loss 0.000002 \n",
      "\n",
      "sample = 932\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00005\n",
      "-288.051 s10000    Loss 0.000010 \n",
      "\n",
      "sample = 933\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00005\n",
      "LR reduced to: 0.00001s 0.000012 \n",
      "-287.679 s10000    Loss 0.000008 \n",
      "\n",
      "sample = 934\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00008\n",
      "LR reduced to: 0.00001s 0.000009 \n",
      "training stopped at it 8173 after 500 iterations without improvement\n",
      "-234.860 s\n",
      "\n",
      "sample = 935\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00006\n",
      "-287.967 s10000    Loss 0.000001 \n",
      "\n",
      "sample = 936\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "-287.743 s10000    Loss 0.000001 \n",
      "\n",
      "sample = 937\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00005\n",
      "-287.410 s10000    Loss 0.000001 \n",
      "\n",
      "sample = 938\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000001 \n",
      "LR reduced to: 0.00000s 0.000001 \n",
      "training stopped at it 9692 after 500 iterations without improvement\n",
      "-277.843 s\n",
      "\n",
      "sample = 939\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00006\n",
      "-287.513 s10000    Loss 0.000003 \n",
      "\n",
      "sample = 940\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00002\n",
      "LR reduced to: 0.00000s 0.000001 \n",
      "LR reduced to: 0.00000s 0.000000 \n",
      "training stopped at it 9485 after 500 iterations without improvement\n",
      "-272.356 s\n",
      "\n",
      "sample = 941\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00010\n",
      "LR reduced to: 0.00001s 0.000001 \n",
      "-233.094 s10000    Loss 0.000000 \n",
      "\n",
      "sample = 942\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00003\n",
      "-292.949 s10000    Loss 0.000005 \n",
      "\n",
      "sample = 943\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000003 \n",
      "training stopped at it 9891 after 500 iterations without improvement\n",
      "-289.689 s\n",
      "\n",
      "sample = 944\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000006 \n",
      "-293.690 s10000    Loss 0.000003 \n",
      "\n",
      "sample = 945\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00005\n",
      "-294.043 s10000    Loss 0.000003 \n",
      "\n",
      "sample = 946\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00004\n",
      "-293.651 s10000    Loss 0.000012 \n",
      "\n",
      "sample = 947\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00004\n",
      "-293.046 s10000    Loss 0.000002 \n",
      "\n",
      "sample = 948\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000033 \n",
      "training stopped at it 2907 after 500 iterations without improvement\n",
      "-74.578 s\n",
      "\n",
      "sample = 949\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000009 \n",
      "training stopped at it 4769 after 500 iterations without improvement\n",
      "-121.642 s\n",
      "\n",
      "sample = 950\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000030 \n",
      "training stopped at it 4533 after 500 iterations without improvement\n",
      "-116.046 s\n",
      "\n",
      "sample = 951\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00006\n",
      "LR reduced to: 0.00001s 0.000001 \n",
      "-256.116 s10000    Loss 0.000001 \n",
      "\n",
      "sample = 952\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00002\n",
      "LR reduced to: 0.00000s 0.000002 \n",
      "training stopped at it 7815 after 500 iterations without improvement\n",
      "-200.284 s\n",
      "\n",
      "sample = 953\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000032 \n",
      "training stopped at it 4419 after 500 iterations without improvement\n",
      "-113.349 s\n",
      "\n",
      "sample = 954\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00005\n",
      "LR reduced to: 0.00001s 0.000003 \n",
      "training stopped at it 9017 after 500 iterations without improvement\n",
      "-230.589 s\n",
      "\n",
      "sample = 955\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00004\n",
      "LR reduced to: 0.00000s 0.000003 \n",
      "-256.725 s10000    Loss 0.000003 \n",
      "\n",
      "sample = 956\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00009\n",
      "LR reduced to: 0.00001s 0.000089 \n",
      "training stopped at it 5687 after 500 iterations without improvement\n",
      "-144.226 s\n",
      "\n",
      "sample = 957\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00011\n",
      "LR reduced to: 0.00001s 0.000036 \n",
      "training stopped at it 3206 after 500 iterations without improvement\n",
      "-81.865 s\n",
      "\n",
      "sample = 958\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00015\n",
      "LR reduced to: 0.00002s 0.000027 \n",
      "training stopped at it 2653 after 500 iterations without improvement\n",
      "-67.457 s\n",
      "\n",
      "sample = 959\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00006\n",
      "LR reduced to: 0.00001s 0.000064 \n",
      "-255.004 s10000    Loss 0.000023 \n",
      "\n",
      "sample = 960\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00006\n",
      "-273.199 s10000    Loss 0.000009 \n",
      "\n",
      "sample = 961\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00006\n",
      "-274.496 s10000    Loss 0.000010 \n",
      "\n",
      "sample = 962\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00005\n",
      "LR reduced to: 0.00001s 0.000024 \n",
      "training stopped at it 8452 after 500 iterations without improvement\n",
      "-230.847 s\n",
      "\n",
      "sample = 963\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00003\n",
      "LR reduced to: 0.00000s 0.000001 \n",
      "-327.296 s10000    Loss 0.000001 \n",
      "\n",
      "sample = 964\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00003\n",
      "-327.963 s10000    Loss 0.000002 \n",
      "\n",
      "sample = 965\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00011\n",
      "LR reduced to: 0.00001s 0.000019 \n",
      "training stopped at it 7139 after 500 iterations without improvement\n",
      "-234.535 s\n",
      "\n",
      "sample = 966\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00010\n",
      "LR reduced to: 0.00001s 0.000026 \n",
      "training stopped at it 3425 after 500 iterations without improvement\n",
      "-112.283 s\n",
      "\n",
      "sample = 967\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00013\n",
      "LR reduced to: 0.00001s 0.000017 \n",
      "-327.617 s10000    Loss 0.000005 \n",
      "\n",
      "sample = 968\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00005\n",
      "LR reduced to: 0.00000s 0.000008 \n",
      "-327.334 s10000    Loss 0.000002 \n",
      "\n",
      "sample = 969\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00003\n",
      "LR reduced to: 0.00000s 0.000001 \n",
      "training stopped at it 8119 after 500 iterations without improvement\n",
      "-175.198 s\n",
      "\n",
      "sample = 970\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000008 \n",
      "-216.405 s10000    Loss 0.000005 \n",
      "\n",
      "sample = 971\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00005\n",
      "LR reduced to: 0.00001s 0.000006 \n",
      "training stopped at it 9408 after 500 iterations without improvement\n",
      "-203.913 s\n",
      "\n",
      "sample = 972\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00002\n",
      "-255.289 s10000    Loss 0.000005 \n",
      "\n",
      "sample = 973\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00004\n",
      "LR reduced to: 0.00000s 0.000013 \n",
      "training stopped at it 7828 after 500 iterations without improvement\n",
      "-200.127 s\n",
      "\n",
      "sample = 974\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00010\n",
      "LR reduced to: 0.00001s 0.000021 \n",
      "training stopped at it 4616 after 500 iterations without improvement\n",
      "-118.367 s\n",
      "\n",
      "sample = 975\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00007\n",
      "LR reduced to: 0.00001s 0.000027 \n",
      "-254.801 s10000    Loss 0.000010 \n",
      "\n",
      "sample = 976\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00005\n",
      "LR reduced to: 0.00000s 0.000012 \n",
      "training stopped at it 5739 after 500 iterations without improvement\n",
      "-148.166 s\n",
      "\n",
      "sample = 977\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00008\n",
      "LR reduced to: 0.00001s 0.000022 \n",
      "training stopped at it 4146 after 500 iterations without improvement\n",
      "-107.750 s\n",
      "\n",
      "sample = 978\n",
      "Finding LR\n",
      "training initialization 0 with LR = 0.00003\n",
      "Iteration 06284    Loss 0.000001 \r"
     ]
    }
   ],
   "source": [
    "LR = 1e-7\n",
    "for idx, new_name in tqdm_notebook(enumerate(files), total=len(files)):\n",
    "    start = time.time()\n",
    "    if idx<878: continue\n",
    "    print(f'sample = {idx}')\n",
    "    idname=new_name[:-4]\n",
    "    \n",
    "    restart = True\n",
    "    restart_i = 0\n",
    "    \n",
    "    lungs_slice, mask_slice, nodule, outside_lungs = read_slices(new_name)\n",
    "    \n",
    "    img_np, img_mask_np, outside_lungs = make_images_right_size(lungs_slice, mask_slice, nodule, outside_lungs)\n",
    "    \n",
    "    # Loss\n",
    "    mse = torch.nn.MSELoss().type(dtype)\n",
    "    \n",
    "    img_var = np_to_torch(img_np).type(dtype)\n",
    "    mask_var = np_to_torch(img_mask_np).type(dtype)\n",
    "    \n",
    "    # LR finder\n",
    "\n",
    "    net = skip(input_depth, img_np.shape[0], \n",
    "           num_channels_down = [128] * 5,\n",
    "           num_channels_up   = [128] * 5,\n",
    "           num_channels_skip = [0] * 5,  \n",
    "           upsample_mode='nearest', filter_skip_size=1, filter_size_up=3, filter_size_down=3,\n",
    "           need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n",
    "\n",
    "    net = net.type(dtype)\n",
    "    \n",
    "    net_input = get_noise(input_depth, INPUT, img_np.shape[1:]).type(dtype)\n",
    "    \n",
    "    \n",
    "    mse_error = []\n",
    "    start = time.time()\n",
    "    i = 0\n",
    "    \n",
    "    net_input_saved = net_input.detach().clone()\n",
    "    noise = net_input.detach().clone()\n",
    "\n",
    "    p = get_params(OPT_OVER, net, net_input)\n",
    "\n",
    "    mse_error, images_generated_all, best_iter = optimize3(OPTIMIZER, p, closure, LR, num_iter, show_every, path_img_dest, restart, annealing=False, lr_finder_flag=True)\n",
    "    \n",
    "    del net\n",
    "    \n",
    "    # Find the longest sequence of slope < -1e-4\n",
    "    loss_going_down = np.where(np.diff(mse_error) < -1e-4)\n",
    "    loss_going_down = list(loss_going_down[0] + 1) \n",
    "    c = count()\n",
    "    val = max((list(g) for _, g in groupby(loss_going_down, lambda x: x-next(c))), key=len)\n",
    "    val = list(val)\n",
    "    LR = LRs[val[-3]] # this is the new LR\n",
    "    \n",
    "    # Training\n",
    "    while restart == True:\n",
    "        \n",
    "        print(f'training initialization {restart_i} with LR = {LR:.5f}')\n",
    "        restart_i += 1\n",
    "        \n",
    "        lungs_slice, mask_slice, nodule, outside_lungs = read_slices(new_name)\n",
    "        img_np, img_mask_np, outside_lungs = make_images_right_size(lungs_slice, mask_slice, nodule, outside_lungs)\n",
    "\n",
    "        # Loss\n",
    "        mse = torch.nn.MSELoss().type(dtype)\n",
    "        img_var = np_to_torch(img_np).type(dtype)\n",
    "        mask_var = np_to_torch(img_mask_np).type(dtype)\n",
    "\n",
    "        net = skip(input_depth, img_np.shape[0], num_channels_down = [128] * 5,\n",
    "                   num_channels_up   = [128] * 5, num_channels_skip = [0] * 5, \n",
    "                   upsample_mode='nearest', filter_skip_size=1, filter_size_up=3, \n",
    "                   filter_size_down=3, need_sigmoid=True, need_bias=True, pad=pad, \n",
    "                   act_fun='LeakyReLU').type(dtype)\n",
    "        net = net.type(dtype)        \n",
    "        net_input = get_noise(input_depth, INPUT, img_np.shape[1:]).type(dtype)\n",
    "        \n",
    "        path_trained_model = f'{path_img_dest}models/v6_Unet_init_sample_{idx}.pt'\n",
    "        torch.save(net.state_dict(), path_trained_model)\n",
    "\n",
    "        mse_error = []\n",
    "        start = time.time()\n",
    "        i = 0\n",
    "        net_input_saved = net_input.detach().clone()\n",
    "        noise = net_input.detach().clone()\n",
    "        p = get_params(OPT_OVER, net, net_input)\n",
    "        mse_error, images_generated_all, best_iter, restart = optimize3(OPTIMIZER, p, closure, LR, num_iter, show_every, path_img_dest, restart, annealing=True, lr_finder_flag=False)\n",
    "    \n",
    "#     factor = 1e11\n",
    "#     mse_error_last = mse_error[-1].detach().cpu().numpy()\n",
    "#     error_final = int((mse_error_last * factor) / np.sum(img_mask_np[0]))\n",
    "\n",
    "        if restart_i % 10 == 0: # reduce lr if the network is not learning with the initializations\n",
    "            LR /= 1.1\n",
    "        if restart_i == 30: # if the network cannot be trained continue (might not act on for loop!!)\n",
    "            continue\n",
    "    del net      \n",
    "    save_original(img_np[0],idname, 'orig')\n",
    "    image_last = images_generated_all[-1][0] * (1-outside_lungs[0])\n",
    "    image_orig = img_np[0] * (1-outside_lungs[0])\n",
    "    best_iter = f'{best_iter:4d}'\n",
    "    save_original(image_last,idname, best_iter)\n",
    "    \n",
    "    np.save(f'{path_img_dest}arrays/last/last {idname}',image_last)\n",
    "    np.save(f'{path_img_dest}arrays/orig/orig {idname}',img_np[0])\n",
    "    stop = time.time()\n",
    "    print(f'{start-stop:.3f} s')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_error_7 = mse_error\n",
    "plt.semilogy(mse_error_1, label='1')\n",
    "plt.semilogy(mse_error_2, label='2')\n",
    "plt.semilogy(mse_error_3, label='3')\n",
    "plt.semilogy(mse_error_4, label='4')\n",
    "plt.semilogy(mse_error_5, label='5')\n",
    "plt.semilogy(mse_error_6, label='6')\n",
    "plt.semilogy(mse_error_7, label='7')\n",
    "plt.ylim([1e-6, 1e-1])\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_error_3 = mse_error\n",
    "plt.semilogy(mse_error_1)\n",
    "plt.semilogy(mse_error_2)\n",
    "plt.semilogy(mse_error_3)\n",
    "plt.ylim([1e-6, 1e-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_error_np = [float(i.detach().cpu().numpy()) for i in mse_error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,10))\n",
    "plt.imshow(images_generated_all[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_error_1 = mse_error_np\n",
    "plt.semilogy(mse_error_1)\n",
    "plt.ylim([1e-5, 1e-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse_3_2 = mse_error\n",
    "plt.semilogy(mse_3_2)\n",
    "plt.semilogy(mse_3, alpha=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using LR = LRs[val[-3]]\n",
    "# 0.00058, 0.00004\n",
    "# using LR = LRs[val[-2]]\n",
    "# 0.00071, 0.00002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{LR:.5f}, {mse_error[-1].detach().cpu().numpy():.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(LRs))\n",
    "plt.semilogx(LRs, mse_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_going_down = np.where(np.diff(mse_error) < -1e-4)\n",
    "loss_going_down = list(loss_going_down[0] + 1) \n",
    "print(loss_going_down)\n",
    "c = count()\n",
    "val = max((list(g) for _, g in groupby(loss_going_down, lambda x: x-next(c))), key=len)\n",
    "val = list(val)\n",
    "print('')\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_error_np = [float(i.detach().cpu().numpy()) for i in mse_error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "plt.semilogx(LRs, mse_error_np)\n",
    "plt.semilogx(LRs[val[0] + offset:val[-1] + offset], \n",
    "             mse_error_np[val[0] + offset:val[-1] + offset],'r')\n",
    "plt.scatter(LRs[val[-2]],mse_error_np[val[-2]], facecolor = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(LRs))\n",
    "print(len(np.diff(mse_error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_error_np = [float(i.detach().cpu().numpy()) for i in mse_error]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0\n",
    "loss_median = len(val)//2 \n",
    "plt.semilogx(LRs, mse_error)\n",
    "plt.semilogx(LRs[val[0] + offset:val[-1] + offset], \n",
    "             mse_error[val[0] + offset:val[-1] + offset], 'r')\n",
    "# plt.scatter(LRs[val[loss_median]], mse_error_np[val[loss_median]])\n",
    "plt.scatter(LRs[val[-2]], mse_error_np[val[-2]])\n",
    "plt.xlim([LRs[30], LRs[130]])\n",
    "LR_new = LRs[val[-2]]\n",
    "print(LR_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.0007778796406007117 * 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(LRs[90:100], mse_error[90:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(outside_lungs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(images_generated_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_errors = [i.detach().cpu().numpy() for i in mse_error]\n",
    "plt.plot(mse_errors[50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idname=new_name[:-4]\n",
    "name_extension = best_iter\n",
    "f'{path_img_dest}gifs/dip {idname} {name_extension:4d}.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(1-img_mask_np[0][60:80,20:60])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = .001\n",
    "for i in range(200):\n",
    "    LR = LR * (0.1**(i//10))\n",
    "    print(LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images_generated_all[-1][0] * (1-outside_lungs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images_generated_all[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mse_error[1000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse4=mse_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mse3[3000:])\n",
    "plt.plot(mse4[3000:],'k')\n",
    "plt.plot(mse_error[3000:], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lng_orig = np.load(f'{path_img_dest}arrays/orig/orig {idname}.npy')\n",
    "lng_last = np.load(f'{path_img_dest}arrays/last/last {idname}.npy')\n",
    "\n",
    "msk_out_lng = np.load(f'{path_data}outside lungs mask/{idname}.npz')\n",
    "msk_out_lng = msk_out_lng.f.arr_0\n",
    "factor = 32\n",
    "pad_dim_0 = factor - nsh(msk_out_lng)[0] % factor\n",
    "pad_dim_1 = factor - nsh(msk_out_lng)[1] % factor\n",
    "msk_out_lng = np.pad(msk_out_lng, ((0,pad_dim_0), (0,0)), mode='constant', constant_values=1)\n",
    "msk_out_lng = np.pad(msk_out_lng, ((0,0), (0,pad_dim_1)), mode='constant', constant_values=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(10,6))\n",
    "ax[0].imshow(a * (1-msk_out_lng))\n",
    "ax[1].imshow(b)\n",
    "ax[2].imshow(b - a * (1-msk_out_lng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(msk_out_lng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all images\n",
    "images_all = os.listdir(f'{path_img_dest}images before gifs/')\n",
    "images_all = np.sort(images_all)\n",
    "_ =[os.remove(f'{path_img_dest}images before gifs/{i}') for i in images_all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images_generated_all[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-7\n",
    "for idx, new_name in tqdm_notebook(enumerate(files), total=len(files)):\n",
    "#     LR *= 1.1\n",
    "#     if LR >= 1: break\n",
    "    if idx==1: break\n",
    "    print(idx)\n",
    "    idname=new_name[:-4]\n",
    "\n",
    "    lungs_slice, mask_slice, nodule, outside_lungs = read_slices(new_name)\n",
    "    img_np, img_mask_np, outside_lungs = make_images_right_size(lungs_slice, mask_slice, nodule, outside_lungs)\n",
    "    \n",
    "#     net = skip(input_depth, img_np.shape[0], \n",
    "#            num_channels_down = [128] * 5,\n",
    "#            num_channels_up   = [128] * 5,\n",
    "#            num_channels_skip = [0] * 5,  \n",
    "#            upsample_mode='nearest', filter_skip_size=1, filter_size_up=3, filter_size_down=3,\n",
    "#            need_sigmoid=True, need_bias=True, pad=pad, act_fun='LeakyReLU').type(dtype)\n",
    "\n",
    "    # Loss\n",
    "    mse = torch.nn.MSELoss().type(dtype)\n",
    "\n",
    "    img_var = np_to_torch(img_np).type(dtype)\n",
    "    mask_var = np_to_torch(img_mask_np).type(dtype)\n",
    "\n",
    "    # LR finder\n",
    "    \n",
    "    net = UNet(num_input_channels=input_depth, num_output_channels=1, \n",
    "                   feature_scale=8, more_layers=1, \n",
    "                   concat_x=True, upsample_mode='deconv', \n",
    "                   pad='zero', norm_layer=torch.nn.InstanceNorm2d, need_sigmoid=True, need_bias=True)\n",
    "        \n",
    "    net = net.type(dtype)\n",
    "    net_input = get_noise(input_depth, INPUT, img_np.shape[1:]).type(dtype)\n",
    "    \n",
    "    mse_error = []\n",
    "    start = time.time()\n",
    "    i = 0\n",
    "    \n",
    "    net_input_saved = net_input.detach().clone()\n",
    "    noise = net_input.detach().clone()\n",
    "\n",
    "    p = get_params(OPT_OVER, net, net_input)\n",
    "\n",
    "    mse_error, images_generated_all, best_iter = optimize2(OPTIMIZER, p, closure, LR, num_iter, show_every, path_img_dest, annealing=False, lr_finder_flag=True)\n",
    "    \n",
    "    # Find the longest sequence of slope < -1e-4\n",
    "    loss_going_down = np.where(np.diff(mse_error) < -1e-4)\n",
    "    loss_going_down = list(loss_going_down[0] + 1) \n",
    "    c = count()\n",
    "    val = max((list(g) for _, g in groupby(loss_going_down, lambda x: x-next(c))), key=len)\n",
    "    val = list(val)\n",
    "    LR = LRs[val[-3]] # this is the new LR\n",
    "    \n",
    "    # Training\n",
    "    print(f'training with LR = {LR:0.5f}\\n')\n",
    "    \n",
    "    lungs_slice, mask_slice, nodule, outside_lungs = read_slices(new_name)\n",
    "    img_np, img_mask_np, outside_lungs = make_images_right_size(lungs_slice, mask_slice, nodule, outside_lungs)\n",
    "    \n",
    "    # Loss\n",
    "    mse = torch.nn.MSELoss().type(dtype)\n",
    "    img_var = np_to_torch(img_np).type(dtype)\n",
    "    mask_var = np_to_torch(img_mask_np).type(dtype)\n",
    "    \n",
    "    net = UNet(num_input_channels=input_depth, num_output_channels=1, \n",
    "                   feature_scale=8, more_layers=1, \n",
    "                   concat_x=True, upsample_mode='deconv', \n",
    "                   pad='zero', norm_layer=torch.nn.InstanceNorm2d, need_sigmoid=True, need_bias=True)\n",
    "    net = net.type(dtype)\n",
    "    net_input = get_noise(input_depth, INPUT, img_np.shape[1:]).type(dtype)\n",
    "    mse_error = []\n",
    "    start = time.time()\n",
    "    i = 0\n",
    "    net_input_saved = net_input.detach().clone()\n",
    "    noise = net_input.detach().clone()\n",
    "    p = get_params(OPT_OVER, net, net_input)\n",
    "    mse_error, images_generated_all, best_iter = optimize2(OPTIMIZER, p, closure, LR, num_iter, show_every, path_img_dest, annealing=False, lr_finder_flag=False)\n",
    "    \n",
    "#     factor = 1e11\n",
    "#     mse_error_last = mse_error[-1].detach().cpu().numpy()\n",
    "#     error_final = int((mse_error_last * factor) / np.sum(img_mask_np[0]))\n",
    "    \n",
    "    save_original(img_np[0],idname, 'orig')\n",
    "    image_last = images_generated_all[-1][0] * (1-outside_lungs[0])\n",
    "    image_orig = img_np[0] * (1-outside_lungs[0])\n",
    "    best_iter = f'{best_iter:4d}'\n",
    "    save_original(image_last,idname, best_iter)\n",
    "    \n",
    "    np.save(f'{path_img_dest}arrays/last/last {idname}',image_last)\n",
    "    np.save(f'{path_img_dest}arrays/orig/orig {idname}',img_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "267.5px",
    "left": "813.988px",
    "right": "20px",
    "top": "118.988px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
